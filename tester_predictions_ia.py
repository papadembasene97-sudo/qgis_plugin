"""
Script de test des prÃ©dictions du modÃ¨le IA
CheminerIndus - Version 1.2.1
"""

import pandas as pd
import joblib
import os

# ============================================
# CONFIGURATION
# ============================================

# âš ï¸ MODIFIER CE CHEMIN SELON VOTRE INSTALLATION
DOSSIER_DONNEES = 'P:/BASES_SIG/ProjetQGIS/model_ia'

FICHIER_MODELE = f'{DOSSIER_DONNEES}/modele_pollution_2026.pkl'
FICHIER_METADATA = f'{DOSSIER_DONNEES}/modele_metadata.pkl'
FICHIER_DONNEES = f'{DOSSIER_DONNEES}/donnees_ia.csv'

# ============================================
# FONCTIONS
# ============================================

def charger_modele(fichier_modele, fichier_metadata):
    """Charge le modÃ¨le et ses mÃ©tadonnÃ©es"""
    print(f"ğŸ“‚ Chargement du modÃ¨le : {fichier_modele}")
    
    if not os.path.exists(fichier_modele):
        raise FileNotFoundError(f"âŒ ModÃ¨le introuvable : {fichier_modele}")
    
    modele = joblib.load(fichier_modele)
    metadata = joblib.load(fichier_metadata)
    
    print(f"âœ“ ModÃ¨le chargÃ©")
    print(f"   - Date d'entraÃ®nement : {metadata['date_entrainement']}")
    print(f"   - PrÃ©cision : {metadata['precision']*100:.1f}%")
    print(f"   - Features : {metadata['nb_features']}")
    
    return modele, metadata

def predire_pollution(modele, metadata, X):
    """PrÃ©dit la probabilitÃ© de pollution pour chaque nÅ“ud"""
    print(f"\nğŸ”® PrÃ©diction en cours sur {len(X)} nÅ“uds...")
    
    # VÃ©rifier que toutes les features sont prÃ©sentes
    feature_names = metadata['feature_names']
    missing_features = set(feature_names) - set(X.columns)
    if missing_features:
        print(f"âš ï¸  Features manquantes : {missing_features}")
        # Ajouter les features manquantes avec valeur 0
        for feature in missing_features:
            X[feature] = 0
    
    # RÃ©organiser les colonnes dans le bon ordre
    X = X[feature_names]
    
    # Remplacer NaN par 0
    X = X.fillna(0)
    
    # PrÃ©dire
    predictions = modele.predict(X)
    probabilites = modele.predict_proba(X)
    
    print("âœ“ PrÃ©dictions terminÃ©es")
    
    return predictions, probabilites

def analyser_predictions(predictions, probabilites):
    """Analyse et affiche les statistiques des prÃ©dictions"""
    print("\n" + "="*60)
    print("ğŸ“Š ANALYSE DES PRÃ‰DICTIONS")
    print("="*60)
    
    # RÃ©partition des prÃ©dictions
    nb_pollution = (predictions == 1).sum()
    nb_pas_pollution = (predictions == 0).sum()
    total = len(predictions)
    
    print(f"\nğŸ“ˆ RÃ©partition des prÃ©dictions :")
    print(f"   Pollution dÃ©tectÃ©e    : {nb_pollution:4d} ({nb_pollution/total*100:5.1f}%)")
    print(f"   Pas de pollution      : {nb_pas_pollution:4d} ({nb_pas_pollution/total*100:5.1f}%)")
    
    # Niveaux de risque
    proba_pollution = probabilites[:, 1] * 100  # ProbabilitÃ© classe 1 (pollution)
    
    critique = (proba_pollution >= 80).sum()
    eleve = ((proba_pollution >= 60) & (proba_pollution < 80)).sum()
    moyen = ((proba_pollution >= 40) & (proba_pollution < 60)).sum()
    faible = (proba_pollution < 40).sum()
    
    print(f"\nğŸ¯ Niveaux de risque :")
    print(f"   CRITIQUE (â‰¥80%)       : {critique:4d} nÅ“uds ğŸ”´")
    print(f"   Ã‰LEVÃ‰ (60-79%)        : {eleve:4d} nÅ“uds ğŸŸ ")
    print(f"   MOYEN (40-59%)        : {moyen:4d} nÅ“uds ğŸŸ¡")
    print(f"   FAIBLE (<40%)         : {faible:4d} nÅ“uds ğŸŸ¢")
    
    return proba_pollution

def afficher_top_risques(df, predictions, probabilites, top_n=20):
    """Affiche les nÅ“uds Ã  plus haut risque"""
    print(f"\nâš ï¸  TOP {top_n} NÅ’UDS Ã€ RISQUE CRITIQUE")
    print("="*60)
    
    # Ajouter les prÃ©dictions au DataFrame
    df_resultat = df.copy()
    df_resultat['prediction'] = predictions
    df_resultat['proba_pollution'] = probabilites[:, 1] * 100
    
    # DÃ©finir le niveau de risque
    def niveau_risque(proba):
        if proba >= 80:
            return 'CRITIQUE ğŸ”´'
        elif proba >= 60:
            return 'Ã‰LEVÃ‰ ğŸŸ '
        elif proba >= 40:
            return 'MOYEN ğŸŸ¡'
        else:
            return 'FAIBLE ğŸŸ¢'
    
    df_resultat['niveau_risque'] = df_resultat['proba_pollution'].apply(niveau_risque)
    
    # Trier par probabilitÃ© dÃ©croissante
    df_top = df_resultat.nlargest(top_n, 'proba_pollution')
    
    # Afficher
    print(f"\n{'Rang':<5} {'ID NÅ“ud':<15} {'Proba':<8} {'Niveau':<15} {'Inversions':<12} {'Industriels':<12} {'Historique'}")
    print("-" * 100)
    
    for i, (idx, row) in enumerate(df_top.iterrows(), 1):
        id_noeud = row.get('id_noeud', f'NÅ“ud_{idx}')
        proba = row['proba_pollution']
        niveau = row['niveau_risque']
        inversions = row.get('nb_inversions_total', 0)
        industriels = row.get('nb_industriels', 0)
        pollutions = row.get('nb_pollutions', 0)
        
        print(f"{i:<5} {str(id_noeud):<15} {proba:6.1f}%  {niveau:<15} {inversions:<12} {industriels:<12} {pollutions}")
    
    return df_resultat

def sauvegarder_predictions(df_resultat, fichier_sortie):
    """Sauvegarde les prÃ©dictions dans un CSV"""
    print(f"\nğŸ’¾ Sauvegarde des prÃ©dictions : {fichier_sortie}")
    
    # SÃ©lectionner les colonnes importantes
    colonnes_sortie = [
        'id_noeud', 'commune', 
        'prediction', 'proba_pollution', 'niveau_risque',
        'nb_inversions_total', 'nb_industriels', 'nb_pollutions',
        'score_risque_calcule'
    ]
    
    # Filtrer les colonnes existantes
    colonnes_existantes = [col for col in colonnes_sortie if col in df_resultat.columns]
    
    df_sortie = df_resultat[colonnes_existantes]
    df_sortie.to_csv(fichier_sortie, index=False, encoding='utf-8-sig')
    
    print(f"âœ“ {len(df_sortie)} prÃ©dictions sauvegardÃ©es")

# ============================================
# PROGRAMME PRINCIPAL
# ============================================

def main():
    """Fonction principale"""
    print("\n" + "="*60)
    print("ğŸ”® TEST DES PRÃ‰DICTIONS - CHEMINER INDUS v1.2.1")
    print("="*60)
    
    try:
        # 1. Charger le modÃ¨le
        modele, metadata = charger_modele(FICHIER_MODELE, FICHIER_METADATA)
        
        # 2. Charger les donnÃ©es de test
        print(f"\nğŸ“‚ Chargement des donnÃ©es : {FICHIER_DONNEES}")
        df = pd.read_csv(FICHIER_DONNEES)
        print(f"âœ“ {len(df)} nÅ“uds chargÃ©s")
        
        # 3. PrÃ©parer les features (sans le label)
        if 'pollution_detectee_label' in df.columns:
            label_reel = df['pollution_detectee_label']
            X = df.drop(['pollution_detectee_label'], axis=1)
        else:
            label_reel = None
            X = df.copy()
        
        # 4. PrÃ©dire
        predictions, probabilites = predire_pollution(modele, metadata, X)
        
        # 5. Analyser les prÃ©dictions
        proba_pollution = analyser_predictions(predictions, probabilites)
        
        # 6. Afficher les nÅ“uds Ã  risque
        df_resultat = afficher_top_risques(df, predictions, probabilites, top_n=20)
        
        # 7. Comparer avec la rÃ©alitÃ© (si disponible)
        if label_reel is not None:
            print("\n" + "="*60)
            print("âœ… COMPARAISON AVEC LA RÃ‰ALITÃ‰")
            print("="*60)
            
            from sklearn.metrics import accuracy_score, confusion_matrix
            
            precision = accuracy_score(label_reel, predictions)
            cm = confusion_matrix(label_reel, predictions)
            
            print(f"\nğŸ¯ PrÃ©cision : {precision*100:.1f}%")
            print(f"\nMatrice de confusion :")
            print(f"   Vrais NÃ©gatifs  : {cm[0,0]:5d}")
            print(f"   Faux Positifs   : {cm[0,1]:5d}")
            print(f"   Faux NÃ©gatifs   : {cm[1,0]:5d}")
            print(f"   Vrais Positifs  : {cm[1,1]:5d}")
        
        # 8. Sauvegarder les rÃ©sultats
        fichier_sortie = f'{DOSSIER_DONNEES}/predictions_resultats.csv'
        sauvegarder_predictions(df_resultat, fichier_sortie)
        
        # RÃ©sumÃ© final
        print("\n" + "="*60)
        print("ğŸ‰ TEST TERMINÃ‰ AVEC SUCCÃˆS !")
        print("="*60)
        print(f"\nğŸ“Š RÃ©sumÃ© :")
        print(f"   â€¢ NÅ“uds analysÃ©s : {len(df)}")
        print(f"   â€¢ NÅ“uds Ã  risque CRITIQUE : {(proba_pollution >= 80).sum()}")
        print(f"   â€¢ Fichier rÃ©sultats : {fichier_sortie}")
        print(f"\nğŸ¯ Prochaines Ã©tapes :")
        print(f"   1. Importer predictions_resultats.csv dans QGIS")
        print(f"   2. Visualiser les nÅ“uds Ã  risque sur la carte")
        print(f"   3. Planifier les visites prioritaires")
        print("\n")
        
    except Exception as e:
        print(f"\nâŒ ERREUR : {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
